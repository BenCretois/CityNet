{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yaml\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classnames = ['biotic', 'anthrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [00:07,  9.59it/s]\n",
      "151it [00:07,  9.65it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "for classname in classnames:\n",
    "    \n",
    "    base_savedir = '/media/michael/SeagateData/alison_data/predictions_%s/' % classname\n",
    "    predictions[classname] = {}\n",
    "\n",
    "    for root, dirnames, filenames in tqdm(os.walk(base_savedir)):\n",
    "\n",
    "        for fname in filenames:\n",
    "\n",
    "            if fname.endswith('.npy'):\n",
    "                P = np.load(root + '/' + fname)[:, 1]\n",
    "\n",
    "                if 'E29' in root:\n",
    "                    sitename = 'E29RR'\n",
    "                else:\n",
    "                    sitename = root.replace('/SM2+', '').split('/')[-1]\n",
    "                \n",
    "                predictions[classname][fname.split('.npy')[0]] = (sitename, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sites = set(xx[0] for xx in predictions['biotic'].values())\n",
    "# to_exclude = set(['Card slot', 'copy', 'Sliced', '250515-010615', 'NOISE'])\n",
    "# set_sites = set([xx for xx in sites if all(yy not in xx for yy in to_exclude)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fname_sites = set()\n",
    "# for xx in predictions['biotic'].keys():\n",
    "#     if 'SE154EE' in xx:\n",
    "#         fname_sites.add('SE154EE')\n",
    "#     else:\n",
    "        \n",
    "#         fname_sites.add(xx.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(fname_sites), len(set_sites)\n",
    "# set_sites = set([xx.replace('_', '') for xx in set_sites])\n",
    "\n",
    "# print fname_sites - set_sites\n",
    "# print set_sites - fname_sites\n",
    "# for xx, yy in zip(sorted(list(fname_sites)), sorted(list(set_sites))):\n",
    "#     print xx, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter by site name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  biotic\n",
      "Found 32004 predictions\n",
      "Found 63 unique sites\n",
      "Class:  anthrop\n",
      "Found 32004 predictions\n",
      "Found 63 unique sites\n"
     ]
    }
   ],
   "source": [
    "summaries = collections.defaultdict(dict)\n",
    "site_filtered = {}\n",
    "\n",
    "to_exclude = ['Card slot', 'copy', 'Sliced', '250515-010615', 'NOISE']\n",
    "\n",
    "\n",
    "for classname in classnames:\n",
    "    \n",
    "    print \"Class: \", classname\n",
    "    print \"Found %d predictions\" % len(predictions[classname])\n",
    "    \n",
    "    site_filtered[classname] = collections.defaultdict(list)\n",
    "\n",
    "    for fname, (sitename, P) in predictions[classname].iteritems():\n",
    "\n",
    "        if all(xx not in sitename for xx in to_exclude):\n",
    "            site_filtered[classname][sitename].append(P)\n",
    "\n",
    "    print \"Found %d unique sites\" % len(site_filtered[classname])\n",
    "\n",
    "    # Summarising per-site\n",
    "    site_summaries = {}\n",
    "    for site, preds in site_filtered[classname].iteritems():\n",
    "        site_summaries[site] = np.nanmean(np.hstack(preds).astype(float))\n",
    "    \n",
    "    # Sorting and printing\n",
    "    site_summaries_l = site_summaries.items()\n",
    "    site_summaries_l = sorted(site_summaries_l, key=lambda x:x[1])\n",
    "\n",
    "    for site, pred in site_summaries_l:\n",
    "\n",
    "        summaries[classname][site] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biotic', 'anthrop']\n"
     ]
    }
   ],
   "source": [
    "print site_filtered.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the summaries to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(summaries)\n",
    "df.to_csv('/home/michael/Dropbox/engage/FairbrassFirmanetal_/data/predictions/massive_dataset/per_site_summaries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the raw data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savedir = '/home/michael/Dropbox/engage/FairbrassFirmanetal_/data/predictions/massive_dataset/raw_predictions/'\n",
    "\n",
    "for site in site_filtered['biotic']:\n",
    "    \n",
    "    dic = {'biotic': np.hstack(site_filtered['biotic'][site]),\n",
    "     'anthrop': np.hstack(site_filtered['anthrop'][site])}\n",
    "\n",
    "    df = pd.DataFrame(dic)\n",
    "\n",
    "    savepath = savedir + site + '.csv'\n",
    "    df.to_csv(savepath, index=False, float_format='%0.5f')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Doing per-site graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_from_fname(fname):\n",
    "    \"\"\"For a single results file, return the predicted activity level\"\"\"\n",
    "    preds = \n",
    "    preds[np.isnan(preds)] = 0\n",
    "    return np.mean(preds)\n",
    "\n",
    "\n",
    "def fname_to_time(fname):\n",
    "    \"\"\"From a filename, extract the time\"\"\"\n",
    "    return fname.split('_')[-2][:4]\n",
    "\n",
    "\n",
    "def datetime_to_decimal(dt):\n",
    "    \"\"\"Convert datetime object to time as hour in decmals\"\"\"\n",
    "    return float(dt.hour) + dt.minute / 60.0\n",
    "\n",
    "\n",
    "def get_times_and_averages(base, classname):\n",
    "    results = collections.defaultdict(list)\n",
    "    for fname in fnames:\n",
    "        if base in fname and classname in fname:\n",
    "            time = fname_to_time(fname)\n",
    "            results[time].append(summary_from_fname(fname))\n",
    "\n",
    "    averages = []\n",
    "    times = []\n",
    "    \n",
    "    # loop over each time and get the keys and summaries\n",
    "    for hour in range(24):\n",
    "        for half in [0, 1]:\n",
    "            key = '%02d%02d' % (hour, half*30)\n",
    "            averages.append(np.mean(results[key]))\n",
    "            times.append(hour + half * 0.5 + 0.25)\n",
    "    return times, averages\n",
    "\n",
    "\n",
    "def plot_results(base, classname):\n",
    "    \"\"\"For a filename base, plot all theresults summaries\"\"\"\n",
    "    times, averages = get_times_and_averages(base, classname)\n",
    "\n",
    "    # Plotting activity levels\n",
    "    plt.plot(times, averages, label=mapper[classname])\n",
    "    plt.xlabel('Hour of day', fontsize=16)\n",
    "    plt.ylabel('Level of activity', fontsize=16)\n",
    "    plt.xlim(0, 24)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks([0, 6, 12, 18, 24], ['00:00', '06:00', '12:00', '18:00', '24:00'], fontsize=14)\n",
    "    #plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], fontsize=14)\n",
    "    plt.yticks([0, 1.0], fontsize=14)\n",
    "\n",
    "    # Plotting sunset/sunrise times\n",
    "    print \"Warning - just using first recording for sunset...\"\n",
    "    datestr = [xx for xx in fnames if xx.startswith(base)][0].split('_')[1]\n",
    "    when = datetime.datetime.strptime(datestr, '%Y%m%d')\n",
    "    sunrise = s.sunrise(when=when)\n",
    "    sunset = s.sunset(when=when)\n",
    "    \n",
    "    sun_colour = np.array([0.9, 0.3, 0.3])\n",
    "    sr = datetime_to_decimal(sunrise)\n",
    "    plt.plot([sr, sr], [0.075, 1], '--', color=sun_colour)\n",
    "    #plt.text(sr - 1.3, 1.01, 'Sunrise', fontsize=16, color=sun_colour)\n",
    "    plt.text(sr - 1.3, .015, 'Sunrise', fontsize=16, color=sun_colour)\n",
    "    \n",
    "    ss = datetime_to_decimal(sunset)\n",
    "    plt.plot([ss, ss], [0.075, 1], '--', color=sun_colour)\n",
    "    plt.text(ss - 1.3, .015, 'Sunset', fontsize=16, color=sun_colour)\n",
    "\n",
    "    \n",
    "def set_up_plot():\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "#     ax = plt.subplot(111)\n",
    "#     box = ax.get_position()\n",
    "#     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
