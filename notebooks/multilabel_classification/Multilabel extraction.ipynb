{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import scipy.io.wavfile\n",
    "from scipy.io import loadmat\n",
    "import collections\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/projects/engaged_hackathon/'))\n",
    "from engaged.features import features as engaged_features\n",
    "from engaged.features import frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we've already created the spectrograms. What we want to do now is to do the full multilabel classification\n",
    "# let's just randomly extract slices...?\n",
    "# then each slice has one or more labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's now for each \n",
    "import helpers\n",
    "all_annotations, fannotations = helpers.load_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MeanAmp': 0.0, 'LabelStartTime_Seconds': 0.0, 'MaximumFreq_Hz': 0.0, 'MaxAmp': 0.0, 'Spec_NStep': 0.01, 'MinAmp': 0.0, 'LabelArea_Datapoints_Threshold': 0.0, 'LabelArea_DataPoints': 0.0, 'Label': 'mix traffic', 'Spec_x2': 0.0, 'length': 59.99, 'AmpSD': 0.0, 'Spec_y1': 0.0, 'LabelEndTime_Seconds': 59.99, 'Spec_NWin': 0.03, 'Spec_x1': 0.0, 'Filename': 'E47EN-013527_20131008_0708.wav', 'LabelTimeStamp': '2015-03-11T13:59:59.413000', 'Spec_y2': 0.0, 'MinimumFreq_Hz': 0.0}\n",
      "['airplane', 'anthropogenic unknown', 'applause', 'bat', 'beep', 'bells', 'bird', 'braking', 'bus emitting', 'coughing', 'dog bark', 'electrical', 'footsteps', 'fox', 'grey squirrel', 'horn', 'invertebrate', 'metal', 'mix traffic', 'mower', 'music', 'rain', 'siren', 'startthecar', 'unknown sound', 'voices', 'whistle', 'wing beats']\n"
     ]
    }
   ],
   "source": [
    "# find out all the classes\n",
    "print all_annotations[0]\n",
    "\n",
    "# maintain a common list of classes. This may come back to bite us in the future, but lets see...\n",
    "classes = sorted(list(set([ann['Label'] for ann in all_annotations])))\n",
    "print classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a sample rate - the labels can be resampled later\n",
    "sr = 44000\n",
    "file_labels = {}\n",
    "spec_path = '/home/michael/projects/engaged_hackathon_data/detection/spectrograms/'\n",
    "slices_per_file = 1000\n",
    "hww = 9\n",
    "spec_size = 128\n",
    "\n",
    "# # I will pre-allocate a numpy array for memory efficiency\n",
    "# numpy_shape = (slices_per_file * len(fannotations), 1, spec_size, 2*hww+1)\n",
    "# if np.prod(np.array(numpy_shape)) > 4e9: raise Exception(\"TOO large!\")\n",
    "# if 'all_slices' in vars(): del all_slices\n",
    "# all_slices = np.zeros(numpy_shape) * np.nan\n",
    "savedir = '/home/michael/projects/engaged_hackathon_data/multilabel_classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # generate labels for each file...\n",
    "# for count, (fname, v) in enumerate(fannotations.iteritems()):\n",
    "    \n",
    "#     labels = collections.defaultdict(lambda : np.zeros(sr*60))\n",
    "    \n",
    "#     for ann in v:\n",
    "#         start = int(ann['LabelStartTime_Seconds'] * float(sr))\n",
    "#         end = int(ann['LabelEndTime_Seconds'] * float(sr))\n",
    "#         labels[ann['Label']][start:end] = 1\n",
    "\n",
    "#     # load in the spectrogram\n",
    "#     D = scipy.io.loadmat(spec_path + fname[:-4] + '_spec_' + str(spec_size) + '.mat')\n",
    "#     spec = D['spectrogram']\n",
    "#     spec_sr = D['sample_rate']\n",
    "    \n",
    "#     # choose random locations in the spectrogram\n",
    "#     locations = np.random.choice(spec.shape[1], slices_per_file, replace=False)\n",
    "        \n",
    "#     # lets extract suitable slices from this dataset\n",
    "#     slices = helpers.extract_1d_patches(spec, locations, hww)\n",
    "#     slices = slices.reshape((slices.shape[0], 1, slices.shape[1], slices.shape[2]))\n",
    "        \n",
    "#     # now give these slices a label...\n",
    "#     keys = labels.keys()\n",
    "#     rescaled_locations = (sr * (locations / float(spec_sr))).astype(int)\n",
    "#     location_labels = [labels[key][rescaled_locations] for key in classes]\n",
    "#     location_labels = np.vstack(location_labels)\n",
    "    \n",
    "#     D = dict(\n",
    "#         slices=slices, \n",
    "#         location_labels=location_labels,\n",
    "#         class_names=classes,\n",
    "#         locations_spec=locations,\n",
    "#         spec_sr=spec_sr,\n",
    "#         locations_wav=rescaled_locations,\n",
    "#         wav_sr=sr)\n",
    "#     savepath = savedir + 'slices/' + fname.replace('.wav', '.mat')\n",
    "    \n",
    "#     scipy.io.savemat(savepath, D, do_compression=True)\n",
    "    \n",
    "#     if count % 10 == 0:\n",
    "#         print count,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now should do the train/test split and then combine labels and slices...\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "split_files = {}\n",
    "split_files['train'], split_files['test'] = train_test_split(\n",
    "    fannotations.keys(), train_size=0.7, test_size=0.3, random_state=10)\n",
    "\n",
    "scipy.io.savemat(savedir + 'split_files.mat', split_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "train\n",
      "(253000, 1, 128, 19) (253000, 1, 28, 1) float32\n",
      "(1000, 1, 128, 19)\n",
      "0 (1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "10 (1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "20 (1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "(1000, 1, 128, 19)\n",
      "30"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cbb18e5c1e3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         D = scipy.io.loadmat(\n\u001b[1;32m---> 33\u001b[1;33m             savedir + 'slices/' + fname.replace('.wav', '.mat'))\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'slices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# add to the slice array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/michael/anaconda/lib/python2.7/site-packages/scipy/io/matlab/mio.pyc\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mMR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mmdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatfile_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/michael/anaconda/lib/python2.7/site-packages/scipy/io/matlab/mio5.pyc\u001b[0m in \u001b[0;36mget_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_var_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mMatReadError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 warnings.warn(\n",
      "\u001b[1;32m/home/michael/anaconda/lib/python2.7/site-packages/scipy/io/matlab/mio5.pyc\u001b[0m in \u001b[0;36mread_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    250\u001b[0m            \u001b[1;33m`\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         '''\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matrix_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_from_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# now load and combine the training and test data separately\n",
    "\n",
    "# creating empty array\n",
    "def create_slice_array(num_slices, spec_height, hww):\n",
    "    numpy_shape = (num_slices, 1, spec_height, 2*hww+1)\n",
    "    if np.prod(np.array(numpy_shape)) > 4e9: raise Exception(\"TOO large!\")\n",
    "    \n",
    "    all_slices = np.zeros(numpy_shape, np.float32) * np.nan\n",
    "    return all_slices\n",
    "\n",
    "\n",
    "for split_name in ['train', 'test']:\n",
    "\n",
    "    print \"\\n\" + split_name\n",
    "    \n",
    "    split = split_files[split_name]\n",
    "\n",
    "    # clear the variable first to prevent memory overflow\n",
    "    if 'all_slices' in vars(): del all_slices\n",
    "    if 'all_labels' in vars(): del all_labels\n",
    "    all_slices = create_slice_array(\n",
    "        slices_per_file * len(split), spec_size, hww)\n",
    "    all_labels = create_slice_array(\n",
    "        slices_per_file * len(split), len(classes), 0)\n",
    "    \n",
    "    print all_slices.shape, all_labels.shape, all_slices.dtype\n",
    "    \n",
    "    # now load in each training slice file one at a time, and add to the slice array...\n",
    "    idx = 0\n",
    "    temp_labs = []\n",
    "    for count, fname in enumerate(split):\n",
    "        D = scipy.io.loadmat(\n",
    "            savedir + 'slices/' + fname.replace('.wav', '.mat'))\n",
    "\n",
    "        # add to the slice array\n",
    "        all_slices[idx:idx+D['slices'].shape[0]] = D['slices']\n",
    "\n",
    "        # add to the label array\n",
    "        all_labels[idx:idx+D['slices'].shape[0], ...] = \\\n",
    "            D['location_labels'].T.reshape((-1, 1, len(classes), 1)).astype(np.float32)\n",
    "\n",
    "        idx += D['slices'].shape[0]\n",
    "        \n",
    "        del D\n",
    "\n",
    "        if count % 10 == 0:\n",
    "            print count,\n",
    "\n",
    "    # write to disk...\n",
    "    D = dict(\n",
    "        slices=all_slices.astype(np.float32),\n",
    "        labels=all_labels.astype(np.int32),\n",
    "        class_names=classes)\n",
    "    print \"WARNING - not saving\"\n",
    "#     helpers.savemat_large(savedir + 'all_' + split_name + '.mat', D, do_compression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
