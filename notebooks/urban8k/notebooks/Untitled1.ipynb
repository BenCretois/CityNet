{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 770 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# IO\n",
    "import cPickle as pickle\n",
    "import yaml\n",
    "\n",
    "# CNN\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import lasagne\n",
    "# import lasagne.layers.cuda_convnet\n",
    "from lasagne import layers\n",
    "\n",
    "sys.path.append('../')\n",
    "import urban8k_helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonlin_choice = lasagne.nonlinearities.leaky_rectify\n",
    "\n",
    "params = yaml.load(open('../default_params.yaml'))\n",
    "params['num_filter_layers'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                        num_dense_layers 3\n",
      "                       num_filter_layers 0\n",
      "                            augment_flip True\n",
      "                                 falloff 0.0586\n",
      "                       epochs_of_initial 35\n",
      "                   initial_learning_rate 0.000605583\n",
      "                     do_median_normalise False\n",
      "                        augment_vol_ramp False\n",
      "                              num_epochs 256\n",
      "                           normalisation ['stowell_half']\n",
      "                          minibatch_size 80\n",
      "                           dense_dropout 0.5\n",
      "                            augment_roll True\n",
      "                            norm_std_std 15\n",
      "                         num_dense_units 800\n",
      "                            filter_sizes 5\n",
      "            final_learning_rate_fraction 0.138658\n",
      "                             pool_size_x 4\n",
      "                           norm_mean_std 40\n",
      "                             num_filters 60\n",
      "                           input_dropout 0.02\n",
      "                    initial_filter_layer False\n",
      "                             pool_size_y 4\n",
      "Making network of input size  (None, 1, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "input_var = T.tensor4('inputs')\n",
    "\n",
    "cnn = helpers.build_cnn(input_var, (128, 1), 1, 10, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "val_X_median 200 test_X_mean 200 test_X_var 200 train_X_median 1600 train_X 1600 train_y 1600 val_y 200 val_X 200 val_X_var 200 test_X_median 200 train_X_mean 1600 val_X_mean 200 train_X_var 1600 test_y 200 test_X 200 There are 2 classes \n",
      "[0 2]\n",
      "1600\n",
      "(1, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "split_num = 2\n",
    "base_path = '/media/michael/Seagate/urban8k/'\n",
    "loadpath = base_path + 'splits_128/split' + str(split_num) + '.pkl'\n",
    "data, num_classes = helpers.load_data(loadpath)\n",
    "\n",
    "for key in ['train_X', 'test_X', 'val_X']:\n",
    "    for types in ['_median', '_mean', '_var']:\n",
    "        for idx in range(len(data[key + types])):\n",
    "            data[key + types][idx] = data[key + types][idx][None, :, None]\n",
    "            \n",
    "    data[key] = data[key + '_median']\n",
    "\n",
    "print len(data['train_X_median'])\n",
    "print data['train_X_median'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "0\n",
      "100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (data['train_y'] == 0).sum()\n",
    "print (data['train_y'] == 9).sum()\n",
    "print (data['val_y'] == 0).sum()\n",
    "print (data['val_y'] == 9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "(1600,)\n",
      "(80, 1, 128, 1) (80,)\n"
     ]
    }
   ],
   "source": [
    "print len(data['train_X_median'])\n",
    "print data['train_y'].shape\n",
    "\n",
    "for A, B in helpers.generate_balanced_minibatches_multiclass(\n",
    "    data['train_X_median'], data['train_y'], \n",
    "    int(params['minibatch_size']), 128, augment_options={},\n",
    "    shuffle=True):\n",
    "    print A.shape, B.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set is of size  925 (1, 1, 1) (143,)\n",
      "\n",
      "                        num_dense_layers 3\n",
      "                       num_filter_layers 0\n",
      "                            augment_flip True\n",
      "                                 falloff 0.0586\n",
      "                       epochs_of_initial 35\n",
      "                   initial_learning_rate 0.000605583\n",
      "                     do_median_normalise False\n",
      "                        augment_vol_ramp False\n",
      "                              num_epochs 256\n",
      "                           normalisation ['stowell_half', 'equal_power']\n",
      "                          minibatch_size 80\n",
      "                           dense_dropout 0.4\n",
      "                            augment_roll True\n",
      "                            norm_std_std 15\n",
      "                         num_dense_units 800\n",
      "                            filter_sizes 5\n",
      "            final_learning_rate_fraction 0.138658\n",
      "                             pool_size_x 4\n",
      "                           norm_mean_std 40\n",
      "                             num_filters 60\n",
      "                           input_dropout 0.01\n",
      "                    initial_filter_layer False\n",
      "                             pool_size_y 4\n",
      "Making network of input size  (None, 1, 128, 1)\n",
      " epoch  train_ls  val_ls   train/val  val_acc  val_auc  train_dur val_dur\n",
      " ------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "import perform_run\n",
    "perform_run.run('./results/', (128, 1), 10, data, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
