{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.misc import imread, imsave\n",
    "import cPickle as pickle\n",
    "import yaml\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib import data_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 475 files\n"
     ]
    }
   ],
   "source": [
    "base = '/media/michael/Engage/data/audio/alison_data/golden_set/'\n",
    "# golden data\n",
    "base = '/media/michael/Engage/data/audio/alison_data/golden_set/'\n",
    "annotation_pkl_dir = base + 'extracted/annotations/'\n",
    "spec_pkl_dir = base + 'extracted/specs/'\n",
    "log_dir = base + 'ml_runs/'\n",
    "\n",
    "# large data\n",
    "large_base = '/media/michael/Engage/data/audio/alison_data/large_dataset/'\n",
    "large_spec_pkl_dir = large_base + 'specs/'\n",
    "large_annotation_pkl_dir = large_base + 'annots/'\n",
    "\n",
    "max_to_load = 1000000\n",
    "\n",
    "# loading the test data filenames - should avoid using these\n",
    "splits = yaml.load(open(base + 'splits/folds.yaml'))\n",
    "test_files = set([f for split in splits for f in split])\n",
    "test_postcodes = set([xx.split('-')[0].split('_')[0] for xx in test_files])\n",
    "\n",
    "# load data and make list of specsamplers\n",
    "fnames_loaded = []\n",
    "\n",
    "num_dropped = 0\n",
    "fnames = os.listdir(large_annotation_pkl_dir)\n",
    "for fname in fnames[:max_to_load]:\n",
    "\n",
    "    if fname.split('-')[0].split('_')[0] in test_postcodes:\n",
    "        num_dropped += 1\n",
    "        continue\n",
    "    fnames_loaded.append(fname)\n",
    "\n",
    "print \"Dropped %d files\" % num_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sites = list(set(xx.split('-')[0].split('_')[0] for xx in fnames_loaded))\n",
    "test_sites = list(set(xx.split('-')[0].split('_')[0] for xx in test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for xx in train_sites:\n",
    "    if len(xx)> 15:\n",
    "        print xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savedir = '/media/michael/Engage/data/audio/alison_data/golden_set/splits/by_site/'\n",
    "with open(savedir + 'golden_test_sites.yaml', 'w') as f:\n",
    "    yaml.dump(test_sites, f, default_flow_style=0)\n",
    "    \n",
    "with open(savedir + 'large_train_sites.yaml', 'w') as f:\n",
    "    yaml.dump(train_sites, f, default_flow_style=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
