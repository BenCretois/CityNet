{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 770 (CNMeM is disabled, cuDNN 5004)\n",
      "/home/michael/anaconda/lib/python2.7/site-packages/Theano-0.9.0.dev1-py2.7.egg/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# creating spectrograms from all the files, and saving split labelled versions to disk ready for machine learning\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import random \n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "#from data_helpers import load_annotations\n",
    "\n",
    "import nolearn\n",
    "import nolearn.lasagne\n",
    "import lasagne.layers\n",
    "\n",
    "from lasagne.layers import InputLayer, DimshuffleLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax, very_leaky_rectify as vlr\n",
    "import theano\n",
    "\n",
    "base = '/media/michael/Seagate/engage/alison_data/golden_set/'\n",
    "annotation_pkl_dir = base + 'extracted/annotations/'\n",
    "spec_pkl_dir = base + 'extracted/specs/'\n",
    "log_dir = base + 'ml_runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HWW = 15\n",
    "SPEC_HEIGHT = 330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a class for the spectrograms, from which we can get minbatches of data\n",
    "class SpecSampler(object):\n",
    "    \n",
    "    def _ensure_correct_shape_spec(self, spec):\n",
    "        if spec.ndim == 2:\n",
    "            return spec[None, ...]\n",
    "        else:\n",
    "            return spec\n",
    "    \n",
    "    def __init__(self, specs, labels, hww):       \n",
    "        self.specs = np.vstack(self._ensure_correct_shape_spec(spec) for spec in specs)\n",
    "        self.labels = labels\n",
    "        self.hww = hww\n",
    "    \n",
    "    def _ensure_shape(self, X):\n",
    "        if X.shape[2] < self.hww * 2:\n",
    "            return np.pad(X, ((0, 0), (0, 0), (0, self.hww * 2 - X.shape[2])), 'constant')\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def sample(self, num_per_class, seed=None):\n",
    "        \n",
    "        tic = time.time()\n",
    "        num_samples = num_per_class * 2\n",
    "        channels = self.specs.shape[0]\n",
    "        height = self.specs.shape[1]\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        X = np.zeros((num_samples, channels, height, self.hww*2), np.float32)\n",
    "        y = np.zeros(num_samples) * np.nan\n",
    "        count = 0\n",
    "        tic = time.time()\n",
    "        \n",
    "        for cls in [0, 1]:\n",
    "            possible_locs = np.where(self.labels==cls)[0]\n",
    "\n",
    "            if len(possible_locs) >= num_per_class:\n",
    "                sampled_locs = np.random.choice(possible_locs, num_per_class, replace=False)\n",
    "\n",
    "                for loc in sampled_locs:\n",
    "                    X[count] = self._ensure_shape(\n",
    "                        self.specs[:, :, (loc-self.hww):(loc+self.hww)])\n",
    "                    y[count] = cls\n",
    "                    count += 1\n",
    "\n",
    "        # remove ones we couldn't get\n",
    "        to_remove = np.isnan(y)\n",
    "        return X[~to_remove], y[~to_remove]\n",
    "        \n",
    "        \n",
    "#ss = SpecSampler([np.log((0.001+ melspec))[None, :100, :]], {0: bio_zoomed}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data and make list of specsamplers\n",
    "samplers = []\n",
    "\n",
    "for fname in os.listdir(spec_pkl_dir):\n",
    "    \n",
    "    # load spectrogram and annotations\n",
    "    spec = pickle.load(open(spec_pkl_dir + fname))[:SPEC_HEIGHT, :]\n",
    "    annots, wav, sample_rate = pickle.load(\n",
    "        open(annotation_pkl_dir + fname))\n",
    "        \n",
    "    # reshape annotations\n",
    "    for classname in annots:\n",
    "        factor = float(spec.shape[1]) / annots[classname].shape[0]\n",
    "        annots[classname] = zoom(annots[classname], factor)\n",
    "        \n",
    "    # create sampler\n",
    "    logspec = np.log(0.001 + spec)\n",
    "    logspec_med = logspec - np.median(logspec, axis=1, keepdims=True)\n",
    "    spec_stack = [logspec_med]#, np.random.rand(*logspec.shape)]\n",
    "    ss = SpecSampler(spec_stack, annots['biotic'], HWW)\n",
    "    samplers.append(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyBatch(nolearn.lasagne.BatchIterator):\n",
    "    def __iter__(self):\n",
    "        bs = self.batch_size\n",
    "        for sampler in self.X:\n",
    "            xb, yb = sampler.sample(bs)\n",
    "            xb = np.hstack((xb, (xb-xb.mean()) / xb.std() ))\n",
    "            \n",
    "            num = xb.shape[0]\n",
    "            xb *= (1.0 + np.random.randn(num, 1, 1, 1) * 0.1)\n",
    "            xb += np.random.randn(num, 1, 1, 1) * 0.05\n",
    "            yield xb.astype(np.float32), yb.astype(np.int32)\n",
    "\n",
    "            \n",
    "class MyBatchTest(nolearn.lasagne.BatchIterator):\n",
    "    def __iter__(self):\n",
    "        bs = self.batch_size\n",
    "        for sampler in self.X:\n",
    "            xb, yb = sampler.sample(bs, seed=10)\n",
    "            xb = np.hstack((xb, (xb-xb.mean()) / xb.std() ))\n",
    "            yield xb.astype(np.float32), yb.astype(np.int32)\n",
    "\n",
    "            \n",
    "class MyTrainSplit(nolearn.lasagne.TrainSplit):\n",
    "    # custom data split\n",
    "    def __call__(self, data, Yb, net):\n",
    "        return samplers[:50], samplers[50:], None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from lasagne.nonlinearities import elu as vlr\n",
    "from lasagne.nonlinearities import softmax, very_leaky_rectify as vlr\n",
    "from lasagne.layers import batch_norm\n",
    "net = {}\n",
    "net['input'] = InputLayer((None, len(spec_stack)+1, SPEC_HEIGHT, HWW*2))\n",
    "\n",
    "net['conv1_1'] = batch_norm(ConvLayer(net['input'], 80, (spec.shape[0] - 5, 6), nonlinearity=vlr))\n",
    "net['pool1'] = PoolLayer(net['conv1_1'], pool_size=(4, 3), stride=(1, 3))\n",
    "net['pool1'] = DropoutLayer(net['pool1'], p=0.5)\n",
    "net['conv1_2'] = batch_norm(ConvLayer(net['pool1'], 80, (1, 3), nonlinearity=vlr))\n",
    "net['pool2'] = PoolLayer(net['conv1_2'], pool_size=(1, 2), stride=(1, 1))\n",
    "net['pool2'] = DropoutLayer(net['pool2'], p=0.5)\n",
    "\n",
    "net['fc6'] = batch_norm(DenseLayer(net['pool2'], num_units=512, nonlinearity=vlr))\n",
    "net['fc6'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "net['fc7'] = batch_norm(DenseLayer(net['fc6'], num_units=512, nonlinearity=vlr))\n",
    "net['fc7'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "net['fc8'] = DenseLayer(net['fc7'], num_units=2, nonlinearity=None)\n",
    "net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "net = nolearn.lasagne.NeuralNet(\n",
    "    layers=net['prob'],\n",
    "    max_epochs=500,\n",
    "    update=lasagne.updates.nesterov_momentum,\n",
    "    update_learning_rate=0.001,\n",
    "    update_momentum=0.975,\n",
    "    verbose=1,\n",
    "    batch_iterator_train=MyBatch(128),\n",
    "    batch_iterator_test=MyBatchTest(128),\n",
    "    train_split=MyTrainSplit(None),\n",
    "    check_input=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 1211138 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #    name  size\n",
      "---  ------  --------\n",
      "  0          2x330x30\n",
      "  1          80x6x25\n",
      "  2          80x6x25\n",
      "  3          80x6x25\n",
      "  4          80x3x8\n",
      "  5          80x3x8\n",
      "  6          80x3x6\n",
      "  7          80x3x6\n",
      "  8          80x3x6\n",
      "  9          80x3x5\n",
      " 10          80x3x5\n",
      " 11          512\n",
      " 12          512\n",
      " 13          512\n",
      " 14          512\n",
      " 15          512\n",
      " 16          512\n",
      " 17          512\n",
      " 18          512\n",
      " 19          2\n",
      " 20          2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m1.03575\u001b[0m       \u001b[32m0.69837\u001b[0m      1.48311      0.62845  8.37s\n",
      "      2       \u001b[36m0.83845\u001b[0m       \u001b[32m0.65431\u001b[0m      1.28143      0.67992  8.20s\n",
      "      3       \u001b[36m0.74591\u001b[0m       0.65768      1.13415      0.71301  8.37s\n",
      "      4       \u001b[36m0.71858\u001b[0m       \u001b[32m0.63381\u001b[0m      1.13375      0.72381  8.53s\n",
      "      5       \u001b[36m0.70630\u001b[0m       0.63610      1.11035      0.71944  8.68s\n",
      "      6       \u001b[36m0.69274\u001b[0m       0.64354      1.07646      0.70933  8.30s\n",
      "      7       \u001b[36m0.67938\u001b[0m       \u001b[32m0.63348\u001b[0m      1.07246      0.71645  8.28s\n",
      "      8       \u001b[36m0.65756\u001b[0m       \u001b[32m0.62221\u001b[0m      1.05681      0.72794  8.26s\n",
      "      9       \u001b[36m0.63956\u001b[0m       \u001b[32m0.62087\u001b[0m      1.03009      0.73392  8.20s\n",
      "     10       \u001b[36m0.62148\u001b[0m       0.62233      0.99864      0.73139  8.02s\n",
      "     11       \u001b[36m0.60212\u001b[0m       0.64552      0.93277      0.73966  8.28s\n",
      "     12       \u001b[36m0.58734\u001b[0m       0.66305      0.88581      0.74265  7.92s\n",
      "     13       \u001b[36m0.56540\u001b[0m       0.67084      0.84282      0.75942  8.33s\n",
      "     14       \u001b[36m0.56121\u001b[0m       0.67512      0.83127      0.76011  8.48s\n",
      "     15       \u001b[36m0.54093\u001b[0m       0.69138      0.78239      0.76930  8.54s\n",
      "     16       \u001b[36m0.52878\u001b[0m       0.71249      0.74216      0.76723  8.77s\n",
      "     17       \u001b[36m0.51205\u001b[0m       0.69346      0.73840      0.77160  8.48s\n",
      "     18       \u001b[36m0.49140\u001b[0m       0.72049      0.68203      0.76218  8.58s\n",
      "     19       \u001b[36m0.47734\u001b[0m       0.83418      0.57223      0.76930  8.33s\n",
      "     20       \u001b[36m0.47143\u001b[0m       0.70623      0.66753      0.77688  8.44s\n",
      "     21       \u001b[36m0.45377\u001b[0m       0.74056      0.61275      0.78608  8.45s\n",
      "     22       \u001b[36m0.43700\u001b[0m       0.77491      0.56393      0.78056  8.28s\n",
      "     23       \u001b[36m0.41901\u001b[0m       0.85186      0.49188      0.78332  8.36s\n",
      "     24       \u001b[36m0.40661\u001b[0m       0.81012      0.50191      0.77528  8.40s\n",
      "     25       \u001b[36m0.40158\u001b[0m       0.92582      0.43375      0.76287  8.38s\n",
      "     26       \u001b[36m0.38134\u001b[0m       0.92825      0.41082      0.78585  8.32s\n",
      "     27       0.40567       0.96635      0.41980      0.78745  8.50s\n",
      "     28       0.42017       0.75221      0.55858      0.76999  8.28s\n",
      "     29       0.40789       0.86387      0.47216      0.76356  8.39s\n",
      "     30       0.38137       0.86690      0.43992      0.78079  8.24s\n",
      "     31       \u001b[36m0.35899\u001b[0m       0.85955      0.41765      0.78585  8.63s\n",
      "     32       0.36875       0.87916      0.41943      0.79021  8.14s\n",
      "     33       \u001b[36m0.35330\u001b[0m       0.82562      0.42792      0.77895  8.52s\n",
      "     34       \u001b[36m0.35274\u001b[0m       0.97243      0.36274      0.77665  8.75s\n",
      "     35       \u001b[36m0.33021\u001b[0m       0.93935      0.35153      0.77780  8.52s\n",
      "     36       0.33177       0.96974      0.34213      0.79205  8.57s\n",
      "     37       \u001b[36m0.31742\u001b[0m       1.02681      0.30914      0.77688  8.65s\n",
      "     38       \u001b[36m0.31719\u001b[0m       1.10750      0.28640      0.77137  8.57s\n",
      "     39       0.32034       0.88479      0.36205      0.78791  8.54s\n",
      "     40       0.32444       0.88257      0.36760      0.77803  8.02s\n",
      "     41       0.33102       0.90637      0.36521      0.74540  8.62s\n",
      "     42       0.33614       0.76896      0.43713      0.74196  8.44s\n",
      "     43       0.35141       0.91757      0.38297      0.68428  8.15s\n",
      "     44       0.36458       1.12033      0.32542      0.66958  8.58s\n",
      "     45       0.36603       0.79430      0.46083      0.73024  8.59s\n",
      "     46       \u001b[36m0.30333\u001b[0m       0.78422      0.38679      0.77252  8.84s\n",
      "     47       \u001b[36m0.24001\u001b[0m       0.68415      0.35082      0.80492  8.91s\n",
      "     48       \u001b[36m0.23504\u001b[0m       1.02013      0.23040      0.75827  9.44s\n",
      "     49       0.24618       0.91320      0.26958      0.76815  8.96s\n",
      "     50       \u001b[36m0.22637\u001b[0m       0.67194      0.33689      0.76976  8.99s\n",
      "     51       0.23049       1.06453      0.21652      0.75322  9.35s\n",
      "     52       \u001b[36m0.20307\u001b[0m       0.94881      0.21402      0.77160  8.74s\n",
      "     53       0.20734       0.70655      0.29345      0.79986  8.69s\n",
      "     54       0.22134       0.88188      0.25099      0.79894  8.99s\n",
      "     55       0.20318       0.78332      0.25938      0.78309  9.25s\n",
      "     56       \u001b[36m0.19463\u001b[0m       0.97460      0.19971      0.77114  8.68s\n",
      "     57       \u001b[36m0.18613\u001b[0m       0.81947      0.22713      0.77551  8.71s\n",
      "     58       0.19057       1.17854      0.16170      0.75115  9.27s\n",
      "     59       0.18865       1.07296      0.17582      0.72174  9.15s\n",
      "     60       \u001b[36m0.18585\u001b[0m       1.02971      0.18049      0.75322  9.23s\n",
      "     61       \u001b[36m0.18046\u001b[0m       0.79554      0.22684      0.77298  8.69s\n",
      "     62       \u001b[36m0.16925\u001b[0m       1.38345      0.12234      0.72449  8.69s\n",
      "     63       0.18678       1.39652      0.13375      0.72587  8.30s\n",
      "     64       0.22198       1.60811      0.13804      0.73208  8.35s\n",
      "     65       0.29253       1.17471      0.24902      0.74632  8.34s\n",
      "     66       0.29107       0.86299      0.33728      0.76310  8.36s\n",
      "     67       0.20854       1.00803      0.20688      0.76034  8.39s\n",
      "     68       0.18950       1.17021      0.16193      0.76402  8.33s\n",
      "     69       \u001b[36m0.16777\u001b[0m       1.25571      0.13361      0.75850  8.49s\n",
      "     70       \u001b[36m0.15309\u001b[0m       1.14271      0.13397      0.77688  8.30s\n",
      "     71       0.18707       1.49701      0.12496      0.77022  8.54s\n",
      "     72       0.17330       0.91291      0.18984      0.76494  8.72s\n",
      "     73       0.19786       2.11611      0.09350      0.71760  8.53s\n",
      "     74       0.18814       1.26135      0.14916      0.75069  8.61s\n",
      "     75       0.17577       0.82242      0.21373      0.74632  8.61s\n",
      "     76       0.19167       0.99839      0.19198      0.69233  8.57s\n",
      "     77       0.17422       0.94131      0.18509      0.73300  8.24s\n",
      "     78       0.15597       1.01184      0.15414      0.77160  8.88s\n",
      "     79       \u001b[36m0.14035\u001b[0m       1.31918      0.10640      0.75597  9.03s\n",
      "     80       0.14796       1.18654      0.12470      0.76402  9.20s\n",
      "     81       0.14428       1.24122      0.11624      0.73024  9.62s\n",
      "     82       \u001b[36m0.13662\u001b[0m       1.72725      0.07910      0.68290  8.49s\n",
      "     83       0.14787       1.43203      0.10326      0.70933  8.26s\n",
      "     84       0.16783       2.75218      0.06098      0.67440  8.81s\n",
      "     85       0.20104       1.36647      0.14712      0.72748  8.35s\n",
      "     86       0.17076       1.26669      0.13481      0.72840  8.70s\n",
      "     87       0.15304       0.97358      0.15719      0.77849  8.55s\n",
      "     88       \u001b[36m0.11092\u001b[0m       1.08897      0.10186      0.78194  8.52s\n",
      "     89       \u001b[36m0.09908\u001b[0m       1.00129      0.09895      0.78952  8.37s\n",
      "     90       \u001b[36m0.08741\u001b[0m       1.10884      0.07883      0.77849  8.92s\n",
      "     91       0.09033       1.31773      0.06855      0.78952  8.74s\n",
      "     92       0.10510       1.91843      0.05478      0.76562  8.32s\n",
      "     93       0.12022       1.46566      0.08202      0.79619  8.24s\n",
      "     94       0.11419       1.70130      0.06712      0.77642  9.09s\n",
      "     95       0.10578       1.18388      0.08935      0.76562  8.74s\n",
      "     96       0.11749       1.56316      0.07516      0.71944  8.71s\n",
      "     97       0.12038       1.43567      0.08385      0.76723  8.57s\n",
      "     98       0.15249       2.13082      0.07157      0.78470  8.85s\n",
      "     99       0.14882       1.38776      0.10724      0.78171  8.55s\n",
      "    100       0.13547       1.09219      0.12404      0.77597  8.96s\n",
      "    101       0.11374       1.41143      0.08059      0.76333  8.94s\n",
      "    102       0.09599       1.67820      0.05720      0.75873  9.13s\n",
      "    103       0.09559       1.18617      0.08059      0.74908  8.99s\n",
      "    104       0.10780       1.82295      0.05913      0.70933  8.68s\n",
      "    105       0.10286       2.05653      0.05001      0.70290  8.74s\n",
      "    106       0.11708       2.37310      0.04934      0.71967  8.65s\n",
      "    107       0.10728       1.13903      0.09418      0.78125  9.16s\n",
      "    108       \u001b[36m0.07138\u001b[0m       1.19888      0.05954      0.77252  8.47s\n",
      "    109       0.07639       1.39196      0.05488      0.78998  8.68s\n",
      "    110       0.07397       1.52948      0.04836      0.77551  8.56s\n",
      "    111       \u001b[36m0.05862\u001b[0m       1.51586      0.03867      0.74173  8.52s\n",
      "    112       \u001b[36m0.05338\u001b[0m       1.52492      0.03500      0.75896  8.91s\n",
      "    113       \u001b[36m0.05052\u001b[0m       1.33893      0.03773      0.78010  8.65s\n",
      "    114       \u001b[36m0.04442\u001b[0m       1.47333      0.03015      0.77114  7.91s\n",
      "    115       \u001b[36m0.04249\u001b[0m       1.49344      0.02845      0.80147  8.71s\n",
      "    116       \u001b[36m0.03750\u001b[0m       1.56156      0.02401      0.78217  8.62s\n",
      "    117       \u001b[36m0.03700\u001b[0m       1.66495      0.02223      0.78194  8.83s\n",
      "    118       \u001b[36m0.03420\u001b[0m       1.61406      0.02119      0.79894  8.73s\n",
      "    119       0.03751       1.62047      0.02314      0.78332  8.17s\n",
      "    120       0.04208       1.51635      0.02775      0.77068  8.09s\n",
      "    121       0.05048       2.33549      0.02161      0.76494  7.83s\n",
      "    122       0.05832       1.99058      0.02930      0.76654  8.14s\n",
      "    123       0.05115       1.33315      0.03837      0.74908  8.06s\n",
      "    124       0.07794       1.56031      0.04995      0.70588  8.51s\n",
      "    125       0.06341       1.90284      0.03332      0.78585  8.84s\n",
      "    126       0.05059       1.67481      0.03021      0.76333  8.85s\n",
      "    127       0.04313       1.91574      0.02251      0.74242  9.24s\n",
      "    128       0.06362       3.12402      0.02037      0.74931  8.97s\n",
      "    129       0.09308       1.72343      0.05401      0.78355  8.93s\n",
      "    130       0.05470       1.45777      0.03752      0.78125  8.64s\n",
      "    131       0.03831       1.67903      0.02282      0.76815  9.10s\n",
      "    132       0.03977       1.88349      0.02112      0.77642  9.18s\n",
      "    133       0.03915       1.49195      0.02624      0.76953  9.08s\n",
      "    134       0.03643       1.75227      0.02079      0.77183  8.86s\n",
      "    135       0.03564       1.53090      0.02328      0.74724  8.87s\n",
      "    136       \u001b[36m0.02967\u001b[0m       1.58519      0.01871      0.76034  8.58s\n",
      "    137       0.03151       1.68356      0.01872      0.77045  9.01s\n",
      "    138       0.03423       1.78002      0.01923      0.75276  9.39s\n",
      "    139       \u001b[36m0.02832\u001b[0m       1.51884      0.01865      0.78148  9.24s\n",
      "    140       0.02889       1.71008      0.01689      0.76356  9.30s\n",
      "    141       0.03155       1.58437      0.01991      0.78125  9.21s\n",
      "    142       0.03277       2.07993      0.01575      0.76654  9.26s\n",
      "    143       0.03547       1.56959      0.02260      0.76999  9.16s\n",
      "    144       \u001b[36m0.02829\u001b[0m       1.62617      0.01740      0.77022  9.35s\n",
      "    145       0.02870       1.63658      0.01754      0.77114  9.23s\n",
      "    146       0.02853       1.79015      0.01594      0.76585  9.40s\n",
      "    147       0.05188       2.97113      0.01746      0.74816  9.22s\n",
      "    148       0.07114       1.88861      0.03767      0.75437  9.07s\n",
      "    149       0.04448       2.02981      0.02192      0.69508  9.21s\n",
      "    150       0.04359       1.73775      0.02508      0.72886  9.37s\n",
      "    151       0.04051       1.94889      0.02078      0.74104  8.99s\n",
      "    152       0.05286       2.98429      0.01771      0.76333  8.82s\n",
      "    153       0.06003       2.02288      0.02967      0.77045  8.23s\n",
      "    154       0.05489       1.77363      0.03095      0.76011  8.75s\n",
      "    155       0.06241       2.05891      0.03031      0.76999  8.88s\n",
      "    156       0.05591       2.21380      0.02526      0.76884  8.88s\n",
      "    157       0.04428       1.75879      0.02518      0.73346  8.69s\n",
      "    158       0.04986       1.52906      0.03261      0.72702  8.85s\n",
      "    159       0.03754       1.60451      0.02339      0.77849  9.08s\n",
      "    160       0.03114       1.75055      0.01779      0.73162  8.88s\n",
      "    161       0.03789       1.67146      0.02267      0.78171  8.78s\n",
      "    162       \u001b[36m0.02370\u001b[0m       1.93753      0.01223      0.71232  9.23s\n",
      "    163       0.03790       1.55345      0.02440      0.76471  9.07s\n",
      "    164       0.04135       1.72877      0.02392      0.76517  9.54s\n",
      "    165       0.02955       2.15513      0.01371      0.69623  9.39s\n",
      "    166       0.03698       2.68280      0.01379      0.66981  9.23s\n",
      "    167       0.04773       2.15584      0.02214      0.70611  9.46s\n",
      "    168       0.08389       2.30153      0.03645      0.76861  9.37s\n",
      "    169       0.06760       2.16528      0.03122      0.70129  9.47s\n",
      "    170       0.06035       1.75992      0.03429      0.74770  9.31s\n",
      "    171       0.04487       1.80905      0.02480      0.68474  8.40s\n",
      "    172       0.05340       2.71120      0.01969      0.64683  8.74s\n",
      "    173       0.06683       2.38409      0.02803      0.66958  9.10s\n",
      "    174       0.05401       2.76223      0.01955      0.66245  9.17s\n",
      "    175       0.07282       2.87008      0.02537      0.65441  9.59s\n",
      "    176       0.06305       3.24194      0.01945      0.64246  9.48s\n",
      "    177       0.09572       2.88462      0.03318      0.64982  9.34s\n",
      "    178       0.08575       3.43214      0.02498      0.63488  9.52s\n",
      "    179       0.11012       3.29806      0.03339      0.61282  9.31s\n",
      "    180       0.11518       2.97605      0.03870      0.63419  8.93s\n",
      "    181       0.14635       2.69182      0.05437      0.62109  8.90s\n",
      "    182       0.13786       3.03838      0.04537      0.60869  8.45s\n",
      "    183       0.14656       3.28808      0.04457      0.60386  8.17s\n",
      "    184       0.18952       3.14582      0.06024      0.60616  8.06s\n",
      "    185       0.20840       2.43006      0.08576      0.61811  7.99s\n",
      "    186       0.17099       1.90731      0.08965      0.63258  7.96s\n",
      "    187       0.15426       2.17615      0.07089      0.58019  7.58s\n",
      "    188       0.16654       1.22130      0.13636      0.64706  8.06s\n",
      "    189       0.14140       1.05830      0.13362      0.73323  7.89s\n",
      "    190       0.12223       1.54881      0.07892      0.72656  8.00s\n",
      "    191       0.12485       1.83565      0.06802      0.70198  7.89s\n",
      "    192       0.11347       1.96078      0.05787      0.71278  8.00s\n",
      "    193       0.09073       1.27650      0.07107      0.76700  8.07s\n",
      "    194       0.04911       1.26155      0.03893      0.71094  7.82s\n",
      "    195       0.03521       1.29377      0.02722      0.70404  8.05s\n",
      "    196       0.03626       1.26418      0.02869      0.77114  7.54s\n",
      "    197       0.04377       1.74340      0.02511      0.74678  7.95s\n",
      "    198       0.04576       1.75590      0.02606      0.73529  7.91s\n",
      "    199       0.03848       1.48541      0.02590      0.77275  7.98s\n",
      "    200       0.02609       1.34667      0.01938      0.77619  7.91s\n",
      "    201       \u001b[36m0.02163\u001b[0m       1.40476      0.01540      0.75942  7.94s\n",
      "    202       0.02531       1.55115      0.01632      0.76976  7.43s\n",
      "    203       0.02205       1.57016      0.01404      0.76540  7.72s\n",
      "    204       \u001b[36m0.02033\u001b[0m       1.51001      0.01346      0.76310  8.00s\n",
      "    205       \u001b[36m0.01580\u001b[0m       1.60206      0.00986      0.76746  7.85s\n",
      "    206       0.01879       1.61061      0.01166      0.77091  7.68s\n",
      "    207       0.01732       1.52967      0.01132      0.77298  8.01s\n",
      "    208       0.01659       1.46443      0.01133      0.76838  7.99s\n",
      "    209       \u001b[36m0.01269\u001b[0m       1.45731      0.00871      0.77872  8.00s\n",
      "    210       0.01435       1.66466      0.00862      0.76425  7.86s\n",
      "    211       0.01795       1.73681      0.01034      0.76953  7.85s\n",
      "    212       0.01631       1.60987      0.01013      0.77367  8.00s\n",
      "    213       0.01343       1.53877      0.00873      0.76149  7.91s\n",
      "    214       0.01550       1.59834      0.00969      0.77252  8.06s\n",
      "    215       0.01455       1.66285      0.00875      0.76769  7.88s\n",
      "    216       \u001b[36m0.01262\u001b[0m       1.59636      0.00791      0.77298  8.10s\n",
      "    217       \u001b[36m0.01093\u001b[0m       1.62189      0.00674      0.76930  7.88s\n",
      "    218       0.01242       1.85172      0.00671      0.75827  7.87s\n",
      "    219       0.01449       1.67825      0.00863      0.76654  7.95s\n",
      "    220       \u001b[36m0.01043\u001b[0m       1.67261      0.00623      0.74563  7.89s\n",
      "    221       0.01459       1.76551      0.00826      0.76172  8.03s\n",
      "    222       0.01352       2.01913      0.00670      0.76792  7.50s\n",
      "    223       0.01493       1.77159      0.00843      0.78148  7.87s\n",
      "    224       0.01269       1.68444      0.00753      0.75345  7.58s\n",
      "    225       0.01079       1.64437      0.00656      0.77252  7.87s\n",
      "    226       \u001b[36m0.00801\u001b[0m       1.74949      0.00458      0.77206  7.64s\n",
      "    227       0.00975       1.73590      0.00562      0.77390  8.06s\n",
      "    228       0.01155       1.72847      0.00668      0.77091  7.63s\n",
      "    229       0.00997       1.90371      0.00524      0.76310  7.91s\n",
      "    230       0.01128       1.69926      0.00664      0.77459  7.82s\n",
      "    231       0.01132       1.95379      0.00579      0.75551  8.05s\n",
      "    232       0.01076       1.96361      0.00548      0.77482  7.40s\n",
      "    233       0.01080       1.87345      0.00576      0.77826  7.59s\n",
      "    234       0.00829       1.88339      0.00440      0.77780  7.74s\n",
      "    235       0.01016       1.76905      0.00574      0.77482  7.79s\n",
      "    236       \u001b[36m0.00777\u001b[0m       1.74554      0.00445      0.76287  7.84s\n",
      "    237       0.01019       2.14796      0.00475      0.77160  8.08s\n",
      "    238       0.01204       1.85471      0.00649      0.76838  7.94s\n",
      "    239       0.01165       1.75848      0.00662      0.77665  7.88s\n",
      "    240       0.00841       1.73087      0.00486      0.76723  7.76s\n",
      "    241       \u001b[36m0.00692\u001b[0m       1.91158      0.00362      0.76402  7.81s\n",
      "    242       0.00910       1.78388      0.00510      0.76356  7.54s\n",
      "    243       0.00755       1.98799      0.00380      0.76241  7.53s\n",
      "    244       0.01009       2.06263      0.00489      0.75551  7.67s\n",
      "    245       0.00781       1.72209      0.00453      0.76838  7.86s\n",
      "    246       0.00722       1.94423      0.00371      0.76631  7.88s\n",
      "    247       0.00754       2.03611      0.00370      0.76861  7.92s\n",
      "    248       0.00823       1.82715      0.00451      0.76792  8.00s\n",
      "    249       0.00876       1.81886      0.00481      0.76494  7.81s\n",
      "    250       \u001b[36m0.00639\u001b[0m       1.94654      0.00328      0.76953  7.98s\n",
      "    251       0.00660       1.70384      0.00387      0.77390  7.96s\n",
      "    252       0.00655       1.78129      0.00368      0.77528  8.14s\n",
      "    253       0.00819       2.04768      0.00400      0.76953  7.93s\n",
      "    254       0.00789       1.95076      0.00405      0.77206  7.97s\n",
      "    255       0.00715       1.80767      0.00395      0.76999  7.57s\n",
      "    256       0.00652       1.78319      0.00366      0.78722  7.49s\n",
      "    257       \u001b[36m0.00601\u001b[0m       1.86550      0.00322      0.77252  7.60s\n",
      "    258       0.00708       2.19106      0.00323      0.77022  7.81s\n",
      "    259       0.00986       1.81955      0.00542      0.76103  7.61s\n",
      "    260       0.00766       2.09346      0.00366      0.76999  7.83s\n",
      "    261       0.00814       1.94635      0.00418      0.77390  7.93s\n",
      "    262       0.00654       1.92047      0.00340      0.77711  7.99s\n",
      "    263       \u001b[36m0.00492\u001b[0m       1.92723      0.00255      0.77367  7.99s\n",
      "    264       0.00507       2.14203      0.00237      0.76540  7.99s\n",
      "    265       0.00678       2.00265      0.00339      0.78079  8.03s\n",
      "    266       0.00801       1.89087      0.00424      0.76034  7.70s\n",
      "    267       0.00813       2.04466      0.00398      0.76448  7.92s\n",
      "    268       0.00620       2.21985      0.00279      0.76080  8.08s\n",
      "    269       0.00549       1.96459      0.00280      0.78424  7.94s\n",
      "    270       0.00615       1.97292      0.00312      0.77665  7.89s\n",
      "    271       0.00763       2.17181      0.00351      0.76953  8.14s\n",
      "    272       0.00722       2.28381      0.00316      0.76815  7.65s\n",
      "    273       0.00556       2.06746      0.00269      0.77895  7.98s\n",
      "    274       \u001b[36m0.00488\u001b[0m       2.07126      0.00236      0.77528  7.63s\n",
      "    275       0.00564       2.03477      0.00277      0.77688  7.92s\n",
      "    276       0.00512       2.13451      0.00240      0.77803  8.32s\n",
      "    277       0.00746       2.03775      0.00366      0.77091  8.43s\n",
      "    278       0.00630       2.30944      0.00273      0.76333  8.59s\n",
      "    279       0.00728       2.14606      0.00339      0.78079  8.67s\n",
      "    280       0.00648       1.97804      0.00328      0.77688  8.93s\n",
      "    281       \u001b[36m0.00460\u001b[0m       1.95845      0.00235      0.77918  8.77s\n",
      "    282       0.00540       2.11974      0.00255      0.77619  9.03s\n",
      "    283       0.00586       2.14502      0.00273      0.77665  8.99s\n",
      "    284       0.00569       2.08892      0.00272      0.77711  9.05s\n",
      "    285       0.00607       2.06808      0.00293      0.77390  9.22s\n",
      "    286       0.00620       2.03316      0.00305      0.77413  9.13s\n",
      "    287       0.00681       1.90871      0.00357      0.77482  9.12s\n",
      "    288       0.00500       2.02596      0.00247      0.76517  9.20s\n",
      "    289       0.00596       2.16381      0.00275      0.77619  9.34s\n",
      "    290       0.00680       1.90923      0.00356      0.78240  9.08s\n",
      "    291       0.00673       2.10489      0.00320      0.77619  8.92s\n",
      "    292       0.00796       2.20046      0.00362      0.77459  8.98s\n",
      "    293       0.00522       1.89066      0.00276      0.75230  8.62s\n",
      "    294       0.00833       2.42228      0.00344      0.75460  8.90s\n",
      "    295       0.00683       2.38847      0.00286      0.76195  8.77s\n",
      "    296       0.00802       2.02839      0.00396      0.76815  9.28s\n",
      "    297       0.00628       2.10799      0.00298      0.75643  9.33s\n",
      "    298       0.00755       2.41229      0.00313      0.75322  9.24s\n",
      "    299       \u001b[36m0.00421\u001b[0m       1.87311      0.00225      0.77252  9.02s\n",
      "    300       0.00423       1.97912      0.00214      0.77757  9.18s\n",
      "    301       \u001b[36m0.00399\u001b[0m       2.04079      0.00195      0.77137  9.16s\n",
      "    302       \u001b[36m0.00367\u001b[0m       2.19610      0.00167      0.77344  9.09s\n",
      "    303       0.00556       1.93483      0.00288      0.77459  9.15s\n",
      "    304       0.00499       2.21603      0.00225      0.77114  8.30s\n",
      "    305       0.00542       2.25865      0.00240      0.77275  9.20s\n",
      "    306       0.00733       2.30159      0.00319      0.77206  9.26s\n",
      "    307       0.00580       2.30366      0.00252      0.77114  9.01s\n",
      "    308       0.00494       2.17712      0.00227      0.77551  9.19s\n",
      "    309       \u001b[36m0.00292\u001b[0m       2.25649      0.00129      0.76976  8.78s\n",
      "    310       0.00445       2.19113      0.00203      0.78194  8.23s\n",
      "    311       0.00472       2.08514      0.00227      0.78470  8.47s\n",
      "    312       0.00495       2.25669      0.00219      0.77390  8.62s\n",
      "    313       0.00412       2.10891      0.00195      0.77688  8.21s\n",
      "    314       0.00556       2.19887      0.00253      0.77022  8.48s\n",
      "    315       0.00456       2.10191      0.00217      0.77665  8.66s\n",
      "    316       0.00454       2.27029      0.00200      0.76149  8.54s\n",
      "    317       0.00365       2.26175      0.00161      0.77390  8.53s\n",
      "    318       0.00420       2.07878      0.00202      0.77597  8.22s\n",
      "    319       0.00316       2.16713      0.00146      0.77459  8.19s\n",
      "    320       0.00537       2.11290      0.00254      0.77436  8.35s\n",
      "    321       \u001b[36m0.00286\u001b[0m       2.16742      0.00132      0.76769  8.37s\n",
      "    322       0.00464       2.07182      0.00224      0.79090  8.54s\n",
      "    323       0.00438       2.00214      0.00219      0.76861  8.41s\n",
      "    324       0.00551       2.16724      0.00254      0.74862  8.46s\n",
      "    325       0.00653       2.41255      0.00271      0.75666  8.59s\n",
      "    326       0.00880       2.77745      0.00317      0.75850  8.22s\n",
      "    327       0.00751       2.07089      0.00363      0.78447  8.64s\n",
      "    328       0.00509       2.08751      0.00244      0.77872  8.28s\n",
      "    329       0.00438       2.35614      0.00186      0.76356  8.43s\n",
      "    330       0.00562       2.04792      0.00274      0.77803  8.67s\n",
      "    331       0.00402       2.10700      0.00191      0.77436  8.27s\n",
      "    332       0.00466       2.14477      0.00217      0.77642  8.34s\n",
      "    333       0.00399       2.23615      0.00178      0.77734  8.45s\n",
      "    334       0.00383       2.13609      0.00180      0.77711  8.51s\n",
      "    335       0.00424       2.07810      0.00204      0.77091  8.57s\n",
      "    336       0.00468       2.58499      0.00181      0.76356  8.50s\n",
      "    337       0.00657       2.18102      0.00301      0.77619  8.17s\n",
      "    338       0.00449       1.95567      0.00230      0.77252  7.61s\n",
      "    339       0.00445       2.27871      0.00195      0.76815  7.79s\n",
      "    340       0.00520       2.18910      0.00238      0.77344  8.16s\n",
      "    341       0.00426       2.28003      0.00187      0.77780  7.82s\n",
      "    342       0.00591       2.14181      0.00276      0.78378  8.10s\n",
      "    343       0.00398       2.01898      0.00197      0.78653  8.09s\n",
      "    344       0.00415       2.04785      0.00203      0.78286  8.03s\n",
      "    345       0.00395       2.43875      0.00162      0.77734  8.13s\n",
      "    346       0.00646       2.13530      0.00302      0.78424  8.25s\n",
      "    347       0.00319       2.09720      0.00152      0.75322  8.18s\n",
      "    348       0.00500       2.31632      0.00216      0.75850  7.99s\n",
      "    349       0.00563       2.35262      0.00239      0.77091  8.06s\n",
      "    350       0.00356       2.13799      0.00167      0.77528  7.90s\n",
      "    351       0.00380       2.34408      0.00162      0.77505  8.09s\n",
      "    352       0.00462       2.32869      0.00198      0.77551  7.93s\n",
      "    353       \u001b[36m0.00266\u001b[0m       2.32442      0.00115      0.77505  7.45s\n",
      "    354       0.00500       2.22538      0.00225      0.77987  7.83s\n",
      "    355       0.00331       2.33441      0.00142      0.78401  8.03s\n",
      "    356       0.00461       2.15393      0.00214      0.78125  8.02s\n",
      "    357       0.00556       2.46335      0.00226      0.78470  8.31s\n",
      "    358       0.00385       2.41363      0.00160      0.76999  8.46s\n",
      "    359       0.00432       2.41940      0.00178      0.76402  8.26s\n",
      "    360       0.00408       2.68078      0.00152      0.75850  7.98s\n",
      "    361       0.00492       2.53628      0.00194      0.77734  7.89s\n",
      "    362       0.00393       2.32157      0.00169      0.78125  8.02s\n",
      "    363       0.00308       2.28841      0.00135      0.77826  8.10s\n",
      "    364       0.00316       2.34997      0.00135      0.77344  8.26s\n",
      "    365       0.00346       2.26618      0.00153      0.78102  7.73s\n",
      "    366       0.00271       2.40356      0.00113      0.77619  8.28s\n",
      "    367       0.00408       2.03230      0.00201      0.78676  8.18s\n",
      "    368       0.00398       2.43191      0.00164      0.77344  8.19s\n",
      "    369       0.00371       2.37319      0.00156      0.77482  7.90s\n",
      "    370       0.00433       2.50369      0.00173      0.77711  8.36s\n",
      "    371       0.00477       2.51363      0.00190      0.77321  8.34s\n",
      "    372       0.00389       2.25710      0.00172      0.77482  8.12s\n",
      "    373       \u001b[36m0.00217\u001b[0m       2.16184      0.00100      0.77895  8.23s\n",
      "    374       0.00440       2.34988      0.00187      0.76861  8.14s\n",
      "    375       0.00440       2.23897      0.00196      0.77229  8.15s\n",
      "    376       0.00363       2.27023      0.00160      0.76700  8.18s\n",
      "    377       0.00481       2.71619      0.00177      0.75276  8.25s\n",
      "    378       0.00338       2.27437      0.00149      0.77574  7.92s\n",
      "    379       0.00335       2.16417      0.00155      0.76930  8.02s\n",
      "    380       0.00345       2.46876      0.00140      0.77413  8.13s\n",
      "    381       0.00345       2.28404      0.00151      0.77321  8.05s\n",
      "    382       0.00423       2.41347      0.00175      0.77091  8.35s\n",
      "    383       0.00457       2.30605      0.00198      0.77114  8.08s\n",
      "    384       0.00414       2.40189      0.00172      0.76654  8.08s\n",
      "    385       0.00492       2.24216      0.00219      0.77597  8.30s\n",
      "    386       0.00417       2.04404      0.00204      0.76562  8.14s\n",
      "    387       0.00453       2.18350      0.00208      0.77114  8.09s\n",
      "    388       0.00231       2.40515      0.00096      0.76057  7.87s\n",
      "    389       0.00274       2.09748      0.00131      0.76976  7.97s\n",
      "    390       0.00305       2.20052      0.00138      0.77505  7.90s\n",
      "    391       0.00488       2.47847      0.00197      0.76654  8.00s\n",
      "    392       0.00334       2.64425      0.00126      0.76241  7.93s\n",
      "    393       0.00438       2.33778      0.00187      0.77160  8.67s\n",
      "    394       0.00367       2.20628      0.00166      0.77574  8.61s\n",
      "    395       0.00329       2.31491      0.00142      0.77826  8.43s\n",
      "    396       0.00347       2.22267      0.00156      0.77252  8.44s\n",
      "    397       0.00282       2.28416      0.00123      0.77505  8.50s\n",
      "    398       0.00445       2.08399      0.00214      0.78079  8.40s\n",
      "    399       0.00367       2.19334      0.00167      0.77895  8.24s\n",
      "    400       0.00339       2.39111      0.00142      0.77895  8.10s\n",
      "    401       0.00450       2.27451      0.00198      0.78309  8.20s\n",
      "    402       0.00293       2.21337      0.00132      0.78217  8.25s\n",
      "    403       0.00387       2.44701      0.00158      0.77275  8.28s\n",
      "    404       0.00336       2.33134      0.00144      0.77551  7.97s\n",
      "    405       0.00403       2.44888      0.00164      0.77528  8.02s\n",
      "    406       0.00240       2.38035      0.00101      0.77436  7.85s\n",
      "    407       0.00365       2.44787      0.00149      0.77734  7.93s\n",
      "    408       0.00364       2.14276      0.00170      0.76080  8.24s\n",
      "    409       0.00250       2.57718      0.00097      0.77114  8.43s\n",
      "    410       0.00452       2.21056      0.00204      0.77780  8.52s\n",
      "    411       0.00414       2.58092      0.00161      0.76976  8.70s\n",
      "    412       0.00433       2.49008      0.00174      0.77390  8.71s\n",
      "    413       0.00365       2.30503      0.00158      0.77688  8.51s\n",
      "    414       0.00221       2.29614      0.00096      0.78631  8.31s\n",
      "    415       0.00248       2.46420      0.00101      0.77665  8.37s\n",
      "    416       0.00234       2.57352      0.00091      0.77022  8.22s\n",
      "    417       0.00273       2.62099      0.00104      0.77459  8.32s\n",
      "    418       0.00291       2.49475      0.00117      0.76287  8.15s\n",
      "    419       0.00519       2.23761      0.00232      0.78791  8.26s\n",
      "    420       \u001b[36m0.00207\u001b[0m       2.29221      0.00090      0.78745  8.45s\n",
      "    421       0.00314       2.29420      0.00137      0.78056  8.47s\n",
      "    422       0.00338       2.32333      0.00145      0.78194  8.58s\n",
      "    423       \u001b[36m0.00198\u001b[0m       2.39278      0.00083      0.77413  8.59s\n",
      "    424       0.00247       2.21470      0.00112      0.77780  8.73s\n",
      "    425       0.00278       2.18541      0.00127      0.77688  8.58s\n",
      "    426       0.00203       2.42816      0.00084      0.76907  8.32s\n",
      "    427       0.00287       2.22967      0.00129      0.77275  8.78s\n",
      "    428       0.00342       2.26696      0.00151      0.76884  8.17s\n",
      "    429       \u001b[36m0.00185\u001b[0m       2.27456      0.00081      0.77987  8.48s\n",
      "    430       0.00266       2.31652      0.00115      0.77528  7.76s\n",
      "    431       0.00204       2.34181      0.00087      0.77528  8.31s\n",
      "    432       0.00320       2.19164      0.00146      0.76494  8.06s\n",
      "    433       0.00406       2.54120      0.00160      0.76241  8.20s\n",
      "    434       0.00317       2.24490      0.00141      0.77344  8.60s\n",
      "    435       0.00328       2.32359      0.00141      0.77642  8.38s\n",
      "    436       0.00278       2.39904      0.00116      0.77183  8.44s\n",
      "    437       0.00210       2.30137      0.00091      0.78562  8.75s\n",
      "    438       0.00306       2.32205      0.00132      0.77734  8.83s\n",
      "    439       0.00191       2.32122      0.00082      0.77413  8.30s\n",
      "    440       \u001b[36m0.00173\u001b[0m       2.34678      0.00074      0.77895  8.58s\n",
      "    441       0.00180       2.30721      0.00078      0.77390  8.68s\n",
      "    442       0.00221       2.48245      0.00089      0.77482  8.34s\n",
      "    443       0.00173       2.30885      0.00075      0.77642  8.56s\n",
      "    444       0.00240       2.21769      0.00108      0.77826  8.40s\n",
      "    445       0.00291       2.27799      0.00128      0.78148  8.32s\n",
      "    446       0.00289       2.27076      0.00127      0.78263  8.66s\n",
      "    447       0.00212       2.35507      0.00090      0.77872  8.15s\n",
      "    448       0.00285       2.49485      0.00114      0.77298  8.26s\n",
      "    449       0.00247       2.51726      0.00098      0.77619  8.02s\n",
      "    450       0.00441       2.34897      0.00188      0.77734  8.45s\n",
      "    451       0.00265       2.26278      0.00117      0.78056  8.22s\n",
      "    452       0.00212       2.23986      0.00095      0.78470  8.30s\n",
      "    453       0.00252       2.44768      0.00103      0.77413  7.76s\n",
      "    454       0.00335       2.61017      0.00128      0.76562  8.02s\n",
      "    455       0.00183       2.60293      0.00070      0.76608  7.85s\n",
      "    456       0.00380       2.58735      0.00147      0.77642  8.13s\n",
      "    457       0.00301       2.35303      0.00128      0.76815  8.17s\n",
      "    458       0.00247       2.45854      0.00101      0.77803  8.17s\n",
      "    459       0.00395       2.48843      0.00159      0.77137  8.51s\n",
      "    460       0.00410       2.49517      0.00164      0.77183  8.14s\n",
      "    461       0.00326       2.52208      0.00129      0.76517  8.40s\n",
      "    462       0.00377       2.21011      0.00171      0.78240  8.30s\n",
      "    463       0.00396       2.32400      0.00170      0.77183  8.20s\n",
      "    464       0.00291       2.58737      0.00112      0.77482  8.34s\n",
      "    465       0.00288       2.51522      0.00114      0.77619  8.14s\n",
      "    466       0.00227       2.47673      0.00092      0.78470  8.08s\n",
      "    467       0.00317       2.52977      0.00125      0.77734  8.08s\n",
      "    468       0.00403       2.35278      0.00171      0.78194  8.33s\n",
      "    469       0.00377       2.33553      0.00161      0.78056  8.15s\n",
      "    470       0.00281       2.24520      0.00125      0.77022  8.17s\n",
      "    471       0.00245       2.37789      0.00103      0.77344  7.99s\n",
      "    472       0.00278       2.29599      0.00121      0.77344  8.29s\n",
      "    473       0.00249       2.65167      0.00094      0.76540  8.61s\n",
      "    474       0.00369       2.18312      0.00169      0.77826  7.96s\n",
      "    475       0.00338       2.48588      0.00136      0.77022  7.92s\n",
      "    476       0.00281       2.34369      0.00120      0.77918  8.22s\n",
      "    477       0.00283       2.22558      0.00127      0.77436  8.06s\n",
      "    478       0.00292       2.35780      0.00124      0.77528  8.17s\n",
      "    479       0.00306       2.18289      0.00140      0.76264  8.06s\n",
      "    480       0.00185       2.43031      0.00076      0.77964  7.77s\n",
      "    481       0.00266       2.39540      0.00111      0.77803  8.11s\n",
      "    482       0.00177       2.42298      0.00073      0.77436  8.17s\n",
      "    483       0.00278       2.22829      0.00125      0.77918  7.93s\n",
      "    484       \u001b[36m0.00170\u001b[0m       2.27258      0.00075      0.78562  7.93s\n",
      "    485       0.00223       2.40803      0.00093      0.78722  7.48s\n",
      "    486       \u001b[36m0.00141\u001b[0m       2.42886      0.00058      0.78056  7.91s\n",
      "    487       0.00369       2.38720      0.00155      0.76356  7.88s\n",
      "    488       0.00335       2.45231      0.00137      0.77987  8.18s\n",
      "    489       0.00361       2.22048      0.00162      0.77619  7.98s\n",
      "    490       0.00183       2.48755      0.00074      0.77045  7.98s\n",
      "    491       \u001b[36m0.00130\u001b[0m       2.41643      0.00054      0.77597  7.99s\n",
      "    492       0.00231       2.36516      0.00098      0.77597  8.18s\n",
      "    493       0.00163       2.41337      0.00068      0.77619  8.03s\n",
      "    494       0.00246       2.56554      0.00096      0.77597  8.13s\n",
      "    495       0.00219       2.28092      0.00096      0.77436  8.12s\n",
      "    496       0.00233       2.54107      0.00092      0.76631  7.73s\n",
      "    497       0.00235       2.44214      0.00096      0.77872  7.63s\n",
      "    498       0.00240       2.46108      0.00098      0.78056  8.01s\n",
      "    499       0.00260       2.31863      0.00112      0.77597  7.49s\n",
      "    500       0.00217       2.38226      0.00091      0.76356  7.80s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<__main__.MyBatchTest object at 0x7f62cb921510>,\n",
       "     batch_iterator_train=<__main__.MyBatch object at 0x7f62cb92aa10>,\n",
       "     check_input=False, custom_epoch_scores=None, custom_scores=None,\n",
       "     layers=[<lasagne.layers.special.NonlinearityLayer object at 0x7f62cb92ab10>],\n",
       "     loss=None, max_epochs=500, more_params={},\n",
       "     objective=<function objective at 0x7f6331c6a320>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f6332e4c9b0>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7f62cbb276c8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f62cb9bd128>],\n",
       "     regression=False,\n",
       "     train_split=<__main__.MyTrainSplit object at 0x7f62cb9b3c90>,\n",
       "     update=<function nesterov_momentum at 0x7f6332e5dc80>,\n",
       "     update_learning_rate=0.001, update_momentum=0.975,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(samplers, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_loss(net):\n",
    "    train_loss = [row['train_loss'] for row in net.train_history_]\n",
    "    valid_loss = [row['valid_loss'] for row in net.train_history_]\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(valid_loss, label='valid loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "plot_loss(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.197185359589, 0.518698018591, 0.581381482387, 0.664551736791, 0.699983182485]\n",
    "x = [100, 500, 1000, 2500, 5000]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
