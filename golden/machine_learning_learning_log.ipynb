{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# creating spectrograms from all the files, and saving split labelled versions to disk ready for machine learning\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import random \n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "#from data_helpers import load_annotations\n",
    "\n",
    "import nolearn\n",
    "import nolearn.lasagne\n",
    "import lasagne.layers\n",
    "\n",
    "from lasagne.layers import InputLayer, DimshuffleLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax, very_leaky_rectify as vlr\n",
    "import theano\n",
    "\n",
    "base = '/media/michael/Seagate/engage/alison_data/golden_set/'\n",
    "annotation_pkl_dir = base + 'extracted/annotations/'\n",
    "spec_pkl_dir = base + 'extracted/specs/'\n",
    "log_dir = base + 'ml_runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HWW = 15\n",
    "SPEC_HEIGHT = 330\n",
    "LEARN_LOG = True\n",
    "DO_AUGMENTATION = False\n",
    "DO_BATCH_NORM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a class for the spectrograms, from which we can get minbatches of data\n",
    "class SpecSampler(object):\n",
    "    \n",
    "    def _ensure_correct_shape_spec(self, spec):\n",
    "        if spec.ndim == 2:\n",
    "            return spec[None, ...]\n",
    "        else:\n",
    "            return spec\n",
    "    \n",
    "    def __init__(self, specs, labels, hww):       \n",
    "        self.specs = np.vstack(self._ensure_correct_shape_spec(spec) for spec in specs)\n",
    "        self.median = np.median(self.specs, 2)\n",
    "        self.labels = labels\n",
    "        self.hww = hww\n",
    "    \n",
    "    def _ensure_shape(self, X):\n",
    "        if X.shape[2] < self.hww * 2:\n",
    "            return np.pad(X, ((0, 0), (0, 0), (0, self.hww * 2 - X.shape[2])), 'constant')\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def sample(self, num_per_class, seed=None):\n",
    "        \n",
    "        tic = time.time()\n",
    "        num_samples = num_per_class * 2\n",
    "        channels = self.specs.shape[0]\n",
    "        height = self.specs.shape[1]\n",
    "        \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        X = np.zeros((num_samples, channels, height, self.hww*2), np.float32)\n",
    "        y = np.zeros(num_samples) * np.nan\n",
    "        count = 0\n",
    "        tic = time.time()\n",
    "        \n",
    "        for cls in [0, 1]:\n",
    "            possible_locs = np.where(self.labels==cls)[0]\n",
    "\n",
    "            if len(possible_locs) >= num_per_class:\n",
    "                sampled_locs = np.random.choice(possible_locs, num_per_class, replace=False)\n",
    "\n",
    "                for loc in sampled_locs:\n",
    "                    X[count] = self._ensure_shape(\n",
    "                        self.specs[:, :, (loc-self.hww):(loc+self.hww)])\n",
    "                    y[count] = cls\n",
    "                    count += 1\n",
    "\n",
    "        # remove ones we couldn't get\n",
    "        to_remove = np.isnan(y)\n",
    "        return X[~to_remove], y[~to_remove].astype(np.int32)\n",
    "        \n",
    "        \n",
    "#ss = SpecSampler([np.log((0.001+ melspec))[None, :100, :]], {0: bio_zoomed}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data and make list of specsamplers\n",
    "samplers = []\n",
    "\n",
    "for fname in os.listdir(spec_pkl_dir):\n",
    "    \n",
    "    # load spectrogram and annotations\n",
    "    spec = pickle.load(open(spec_pkl_dir + fname))[:SPEC_HEIGHT, :]\n",
    "    annots, wav, sample_rate = pickle.load(\n",
    "        open(annotation_pkl_dir + fname))\n",
    "        \n",
    "    # reshape annotations\n",
    "    for classname in annots:\n",
    "        factor = float(spec.shape[1]) / annots[classname].shape[0]\n",
    "        annots[classname] = zoom(annots[classname], factor)\n",
    "        \n",
    "    # create sampler\n",
    "    if not LEARN_LOG:\n",
    "        spec = np.log(0.001 + spec)\n",
    "        spec = spec - np.median(spec, axis=1, keepdims=True)\n",
    "\n",
    "    spec_stack = [spec]#, np.random.rand(*logspec.shape)]\n",
    "    ss = SpecSampler(spec_stack, annots['anthrop'], HWW)\n",
    "    ss.fname = fname\n",
    "    samplers.append(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.8816 (20, 1, 330, 30) 20\n"
     ]
    }
   ],
   "source": [
    "class MyBatch(nolearn.lasagne.BatchIterator):\n",
    "    def __iter__(self):\n",
    "        bs = self.batch_size\n",
    "        for sampler in self.X:\n",
    "            xb, yb = sampler.sample(bs)\n",
    "            \n",
    "            num = xb.shape[0]\n",
    "        \n",
    "            # augmentation\n",
    "            if DO_AUGMENTATION:\n",
    "                xb *= (1.0 + np.random.randn(num, 1, 1, 1) * 0.1)\n",
    "                xb += np.random.randn(num, 1, 1, 1) * 0.05\n",
    "\n",
    "            if LEARN_LOG:\n",
    "                # get medians\n",
    "                meds = np.tile(sampler.median, (num, 1, 1))\n",
    "                meds = np.tile(meds[:, :, :, None], (1, 1, 1, HWW*2))\n",
    "\n",
    "                yield {'input': xb.astype(np.float32),\n",
    "                      'input_med': meds.astype(np.float32)}, yb\n",
    "            else:\n",
    "                yield xb.astype(np.float32), yb\n",
    "\n",
    "            \n",
    "class MyBatchTest(nolearn.lasagne.BatchIterator):\n",
    "    def __iter__(self):\n",
    "        bs = self.batch_size\n",
    "        for sampler in self.X:\n",
    "            xb, yb = sampler.sample(bs, seed=10)\n",
    "\n",
    "            if LEARN_LOG:\n",
    "                meds = np.tile(sampler.median, (xb.shape[0], 1, 1))\n",
    "                meds = np.tile(meds[:, :, :, None], (1, 1, 1, HWW*2))\n",
    "                yield {'input': xb.astype(np.float32),\n",
    "                      'input_med': meds.astype(np.float32)}, yb\n",
    "            else:\n",
    "                yield xb.astype(np.float32), yb\n",
    "                \n",
    "\n",
    "mb = MyBatch(20)\n",
    "mb.X = samplers\n",
    "\n",
    "for count, (xx, yy) in enumerate(mb):\n",
    "    if LEARN_LOG:\n",
    "        print xx['input'].max(), xx['input_med'].shape, yy.sum()\n",
    "    else:\n",
    "        print xx.shape, yy.sum(), xx.sum()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import yaml             \n",
    "# splits \n",
    "splits = yaml.load(open(base + 'splits/folds.yaml'))\n",
    "train = splits[0] + splits[1]\n",
    "test = splits[2]\n",
    "                \n",
    "class MyTrainSplit(nolearn.lasagne.TrainSplit):\n",
    "    # custom data split\n",
    "    def __call__(self, data, Yb, net):\n",
    "        train_samplers = [xx for xx in samplers if xx.fname in train]\n",
    "        test_samplers = [xx for xx in samplers if xx.fname in test]\n",
    "        print len(train_samplers), len(test_samplers)\n",
    "        return train_samplers, test_samplers, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from lasagne.nonlinearities import elu as vlr\n",
    "from lasagne.nonlinearities import softmax, very_leaky_rectify as vlr\n",
    "from lasagne.layers import batch_norm, ElemwiseSumLayer, ExpressionLayer, DimshuffleLayer\n",
    "from helpers import Log1Plus, ForgetSizeLayer\n",
    "import theano.tensor as T\n",
    "\n",
    "if not DO_BATCH_NORM:\n",
    "    batch_norm = lambda x: x\n",
    "net = {}\n",
    "\n",
    "# main input layer, then logged\n",
    "net['input'] = InputLayer((None, len(spec_stack), SPEC_HEIGHT, HWW*2), name='input')\n",
    "\n",
    "if LEARN_LOG:\n",
    "    off = lasagne.init.Constant(0.5)\n",
    "    mult = lasagne.init.Constant(1.0)\n",
    "\n",
    "    net['input_logged'] = Log1Plus(net['input'], off, mult)\n",
    "\n",
    "    # logging the median and multiplying by -1\n",
    "    net['input_med'] = InputLayer((None, len(spec_stack), SPEC_HEIGHT, HWW*2), name='input_med')\n",
    "    net['med_logged'] = Log1Plus(net['input_med'], off=net['input_logged'].off, mult=net['input_logged'].mult)\n",
    "    net['med_logged'] = ExpressionLayer(net['med_logged'], lambda X: -X)\n",
    "\n",
    "    # summing the logged input with the negative logged median\n",
    "    net['input'] = ElemwiseSumLayer((net['input_logged'], net['med_logged']))\n",
    "\n",
    "net['conv1_1'] = batch_norm(\n",
    "    ConvLayer(net['input'], 80, (spec.shape[0] - 5, 6), nonlinearity=vlr))\n",
    "net['pool1'] = PoolLayer(net['conv1_1'], pool_size=(2, 2), stride=(2, 2), mode='max')\n",
    "net['pool1'] = DropoutLayer(net['pool1'], p=0.5)\n",
    "net['conv1_2'] = batch_norm(ConvLayer(net['pool1'], 80, (1, 3), nonlinearity=vlr))\n",
    "# net['pool2'] = PoolLayer(net['conv1_2'], pool_size=(1, 2), stride=(1, 1))\n",
    "net['pool2'] = DropoutLayer(net['conv1_2'], p=0.5)\n",
    "\n",
    "net['fc6'] = batch_norm(DenseLayer(net['pool2'], num_units=512, nonlinearity=vlr))\n",
    "net['fc6'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "net['fc7'] = batch_norm(DenseLayer(net['fc6'], num_units=512, nonlinearity=vlr))\n",
    "net['fc7'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "net['fc8'] = DenseLayer(net['fc7'], num_units=2, nonlinearity=None)\n",
    "net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "net = nolearn.lasagne.NeuralNet(\n",
    "    layers=net['prob'],\n",
    "    max_epochs=500,\n",
    "    update=lasagne.updates.adam,\n",
    "    update_learning_rate=0.0001,\n",
    "#     update_momentum=0.975,\n",
    "    verbose=1,\n",
    "    batch_iterator_train=MyBatch(128),\n",
    "    batch_iterator_test=MyBatchTest(128),\n",
    "    train_split=MyTrainSplit(None),\n",
    "    check_input=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 14\n",
      "# Neural Network with 1669540 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  ---------  --------\n",
      "  0  input      1x330x30\n",
      "  1             1x330x30\n",
      "  2  input_med  1x330x30\n",
      "  3             1x330x30\n",
      "  4             1x330x30\n",
      "  5             1x330x30\n",
      "  6             80x6x25\n",
      "  7             80x6x25\n",
      "  8             80x6x25\n",
      "  9             80x3x12\n",
      " 10             80x3x12\n",
      " 11             80x3x10\n",
      " 12             80x3x10\n",
      " 13             80x3x10\n",
      " 14             80x3x10\n",
      " 15             512\n",
      " 16             512\n",
      " 17             512\n",
      " 18             512\n",
      " 19             512\n",
      " 20             512\n",
      " 21             512\n",
      " 22             512\n",
      " 23             2\n",
      " 24             2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m1.07726\u001b[0m       \u001b[32m0.84249\u001b[0m      1.27866      0.42773  2.51s\n",
      "      2       \u001b[36m0.83687\u001b[0m       \u001b[32m0.79841\u001b[0m      1.04816      0.45480  2.46s\n",
      "      3       \u001b[36m0.69005\u001b[0m       \u001b[32m0.75676\u001b[0m      0.91185      0.48465  2.46s\n",
      "      4       \u001b[36m0.62300\u001b[0m       \u001b[32m0.60535\u001b[0m      1.02915      0.63756  2.46s\n",
      "      5       \u001b[36m0.55624\u001b[0m       \u001b[32m0.60401\u001b[0m      0.92091      0.63030  2.49s\n",
      "      6       \u001b[36m0.51065\u001b[0m       \u001b[32m0.56374\u001b[0m      0.90583      0.69420  2.47s\n",
      "      7       \u001b[36m0.48138\u001b[0m       \u001b[32m0.53038\u001b[0m      0.90762      0.70536  2.46s\n",
      "      8       \u001b[36m0.47736\u001b[0m       \u001b[32m0.51777\u001b[0m      0.92194      0.72907  2.46s\n",
      "      9       \u001b[36m0.46428\u001b[0m       \u001b[32m0.47439\u001b[0m      0.97868      0.76646  2.46s\n",
      "     10       \u001b[36m0.44728\u001b[0m       \u001b[32m0.46634\u001b[0m      0.95911      0.75949  2.46s\n",
      "     11       0.44804       \u001b[32m0.46543\u001b[0m      0.96265      0.76451  2.46s\n",
      "     12       0.45244       \u001b[32m0.46244\u001b[0m      0.97838      0.76144  2.47s\n",
      "     13       \u001b[36m0.42287\u001b[0m       \u001b[32m0.44931\u001b[0m      0.94114      0.76423  2.47s\n",
      "     14       0.42884       0.45316      0.94634      0.76674  2.47s\n",
      "     15       \u001b[36m0.41946\u001b[0m       \u001b[32m0.44850\u001b[0m      0.93526      0.76004  2.47s\n",
      "     16       \u001b[36m0.41494\u001b[0m       0.45143      0.91917      0.76395  2.46s\n",
      "     17       \u001b[36m0.40866\u001b[0m       0.45038      0.90736      0.77009  2.47s\n",
      "     18       0.40909       \u001b[32m0.44302\u001b[0m      0.92342      0.76674  2.46s\n",
      "     19       \u001b[36m0.40337\u001b[0m       0.47850      0.84299      0.75586  2.46s\n",
      "     20       0.41080       0.44390      0.92543      0.76646  2.46s\n",
      "     21       0.40577       0.44386      0.91419      0.75670  2.46s\n",
      "     22       0.40967       0.46240      0.88597      0.75921  2.46s\n",
      "     23       \u001b[36m0.39688\u001b[0m       0.46372      0.85585      0.72015  2.46s\n",
      "     24       0.39840       \u001b[32m0.43053\u001b[0m      0.92536      0.76144  2.48s\n",
      "     25       \u001b[36m0.39097\u001b[0m       0.44551      0.87758      0.76256  2.48s\n",
      "     26       \u001b[36m0.37501\u001b[0m       0.45951      0.81609      0.75893  2.46s\n",
      "     27       0.38413       0.43586      0.88133      0.76618  2.46s\n",
      "     28       0.39057       0.45330      0.86160      0.73075  2.47s\n",
      "     29       \u001b[36m0.37256\u001b[0m       0.44599      0.83534      0.74888  2.46s\n"
     ]
    }
   ],
   "source": [
    "net.fit(samplers, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'log1plus1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-00239e059ea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log1plus1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log1plus3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log1plus1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log1plus3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/michael/anaconda/lib/python2.7/site-packages/nolearn-0.6a0.dev0-py2.7.egg/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mLayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'log1plus1'"
     ]
    }
   ],
   "source": [
    "print net.layers_['log1plus1'].off.get_value()\n",
    "print net.layers_['log1plus3'].off.get_value()\n",
    "print net.layers_['log1plus1'].mult.get_value()\n",
    "print net.layers_['log1plus3'].mult.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_loss(net):\n",
    "    train_loss = [row['train_loss'] for row in net.train_history_]\n",
    "    valid_loss = [row['valid_loss'] for row in net.train_history_]\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(valid_loss, label='valid loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "plot_loss(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.197185359589, 0.518698018591, 0.581381482387, 0.664551736791, 0.699983182485]\n",
    "x = [100, 500, 1000, 2500, 5000]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
